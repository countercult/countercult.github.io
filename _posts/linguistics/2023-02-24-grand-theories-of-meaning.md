---
layout: page-fullwidth
title:  "Grand theories of meaning"
teaser: "Is there a grand theory of meaning? No. But we can piece together different scientific traditions to try and make sense of the puzzle."
breadcrumb: true
categories:
    - linguistics
    - ai
    - semantics
permalink: /blog/theories-of-meaning/
header: no
image:
    title: blog/pexels-yaroslav-danylchenko-4113084.jpg
    frontpage: blog/pexels-yaroslav-danylchenko-4113084.jpg
    
---

[...]

Yes, both humans and machines engage in ‘thinking’ and learn a wealth of concepts in a very similar fashion. But when we take thinking apart into its semantic components – meanings and functions over meanings – it becomes clear that many types of thinking are possible, and that machines and humans do not necessarily implement the same type. To arrive at that conclusion, we should stop dwelling on the (temporary) mathematics that power the state-of-the-art in machine learning. Rather, we should strive to explain the (eternal) mathematics that help represent different kinds of thought. Metaphorically speaking, if most publications on AI describe the satellites and shuttles that measure and interact with the universe of meaning, we will be interested here in an account of space itself, and of the orbits of planets.


## A grand theory of meaning?

Before anyone asks, there is no ‘grand computational theory of meaning’. We might in fact argue that there is no unified theory of meaning – computational or otherwise. So whoever is looking for the computational semantics equivalent of the theory of evolution, of Newtonian or Einstein physics, of radioactivity or thermodynamics, is bound to experience some initial disappointment. In place of a single narrative, they will find a collection of practices, intuitions and know-hows which, despite having made their way into the state-of-the-art AI systems operated by the largest companies on the globe, still fail to explain the human mind. In spite of this, if we follow the threads that run through the history and practices of the field, a picture emerges. One that is perhaps best told as a metaphor involving space, worlds, motion, and relativity. The science of meaning undertakes to pull those threads together, interweaving four core hypotheses of computational and theoretical semantics:

(1) Both computational linguistics and cognitive neuroscience tell us that meanings are objects that live in space. A space that resembles the familiar three-dimensional environment we live in, just in many more dimensions (probably a few hundreds). Each point in that space is a potential position for a meaning, providing a cartographic tool for a person’s concepts. Some concepts, like  cat and dog tend to live close to each other, reflecting their similarity; others, like black cat and broken car, will settle in separate regions of the multidimensional space. The space of meanings can be conceptualised in different ways: as an abstract mathematical object, as the neurons in an artificial neural network, or as the neurons in the human brain. It is possible to convert meanings from their mathematical representations to their artificial neural incarnation, to a map of brain activity, and back.

(2) Meanings are dynamic. They emerge and they change, popping into the void of their native space and moving through it. Whenever a meaning emerges or changes its position, a human learns, adapts or invents. Big questions include: How and why did meanings emerge in the process of language evolution? How do they emerge over and over again, in every human baby? How and why do they change, as generations of humans succeed each other? To what extent are they really passed from one brain to another in the process of communication?

(3) The multi-dimensional space of meaning is structured to resemble the four-dimensional space of our perceived reality, but also to allow the human brain to move beyond it. When put together, meanings make up worlds, real and unreal. Possible worlds (both the universe of Star Wars and the scientific theories of the next century) are a consequence of the dynamicity of meaning through space. The truth of a statement can always be computed for a particular configuration of meanings in a particular world, allowing for logical reasoning in a given context.

(4) In the same way that our physical space-time is dependent on the motion of an observer, meanings are relative to the (spatial) context in which they are observed. The star-like object that represents the word cat is not located in the same position for you and me. This is why you fight with your friends about the meaning of freedom, and this is the reason why poetry moves you, frustrates you, and sometimes leaves you behind.

[...]

## Name-dropping

Theoretical and computational linguistics both have colourful histories. The book introduces prominent and less prominent figures, showing their contributions (or sometimes, anti-contributions) to the way computers encode meaning today. Let us start with Noam Chomsky – famous for his cognitively-inspired theory of syntax, his staunch support of anarchist theories, and his absolute dislike of anything related to meaning. In spite of being the anti-semanticist par excellence, Chomsky is a perfect introduction to core questions about language, many of which have an impact on the way computational semantics systems are built: Which parts of the language faculty are innate, and which are learned from experience? If ‘knowing one’s language’ involves being competent in following a given set of rules, how come real linguistic data is so full of deviant usages, and how will a machine understand – let alone generate – them? If the rules of language let us generate an infinity of sentences, do they also supply the infinity of thoughts expressed by those sentences? Does this mean your head contains the thoughts of people who will live after you?

As a counterpart to the Chomskian tradition, meet mathematician and philosopher Richard Montague, founder of mathematical approaches to semantics, real estate investor, Bentley owner, resident of Beverly Hills, member of the Los Angeles gay scene, tragically murdered in his own home in yet unresolved circumstances. Trained by philosopher Alfred Tarski, Montague will famously claim that ‘no important theoretical difference exists between formal and natural languages’, implying that languages like English and Japanese – and in particular the meaning of their sentences – can be described using the tools of logic. This will have profound consequences for the way the world out there (you, your dog, your house, what you did yesterday and might do tomorrow) can be written as a set of formulae, and therefore encoded in a machine.

Crossing the Atlantic, meet also the close circle of philosopher Ludwig Wittgenstein, in particular Margaret Masterman, founder of the Cambridge Language Research Unit (CLRU), one of the first research lab involved in computational linguistics, tucked in a little museum hosting Far Eastern art and adorned with Buddhist sculptures. We encounter CLRU member Yorick Wilks, critic of the Chomskian idea of ‘meaning as a grammar’, and author of over 700 papers, with titles such as ‘Stone Soup and the French Room’ and ‘Is there content in empty heads?’ Most significantly, we get to know Karen Spärck-Jones, another CLRU member, inventor of the so-called ‘TF-IDF’ measure, a technique essential to the development of early Web search engines, and the first person to put meaning in high-dimensional vector spaces.

[...]

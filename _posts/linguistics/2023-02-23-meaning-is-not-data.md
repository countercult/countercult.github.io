---
layout: page-fullwidth
title:  "Data, oil, and less dirty things"
teaser: ""
breadcrumb: true
categories:
    - linguistics
    - ai
permalink: /blog/data-oil-and-less-dirty-things/
header: no
image:
    title: blog/pexels-yaroslav-danylchenko-4113084.jpg
    frontpage: blog/pexels-yaroslav-danylchenko-4113084.jpg
    
---


## Meaning and the new oil

Okay, oil is bad and oil is dead. Welcome green energies. But the metaphor of 'data as the new oil' still lives on.[...]

Meaning – and not data, as some would have it – is the new oil.

The difference between data and meaning is similar to the difference between petroleum reservoirs and refined oil. It is advantageous for governments and companies to own or control land containing crude oil, but without the equipment and know-how to extract and refine the hydrocarbons, there is nothing to sell to consumers. So large corporations like Total, BP and Exxon Mobil invest millions in technologies to locate, extract and prepare oil for consumption. Similarly, owning large amounts of data supposedly gives companies an edge in the new ‘digital age’. But without techniques and people to turn that data into the fuel of machine learning algorithms, the edge is lost. 

When petrochemists refine crude oil, they look for certain properties in the extracted substance: purity and stability, for instance. Data, too, is only really useful if it can be refined into a special kind of artificial substance which exhibits certain properties and ideally agrees with human behaviour, or even better, can be directly mapped to the electrical activity of the brain. In the same way that Total and BP need the fundamental science of chemistry to understand the behaviour of hydrocarbons, Google and Amazon need a fundamental science that explains how the mind represents the raw data it receives from the world and interprets its representations.

As it happens, semantics – the science of meaning – does just that. For humans, meaning is the glue binding the world around us and turning it into a structured collection of manipulable mental objects which we can name, describe, and combine into novel ideas. The natural phenomenon has evolved to encode just the right properties: our semantic faculty lets us map anything from single objects to events, relationships and entire narratives into brain activity. The representations obtained through this process are highly versatile, amenable both to the wild associations of poetry and the logical arguments of science. They are at the source of all human thoughts and underlie everything that our species has ever done.

So if meaning is so important, why have you never heard about it? Why do corporations currently advertise their latest AIs in terms of ‘general intelligence’, ‘problem solving’, or even ‘machine consciousness’, and not in terms of semantics? For the same reason that BP sells ‘gasoline’ and that you put ‘petrol’ or ‘gas’ in your car rather than a mix of ‘paraffins’, ‘olefins’ and ‘cycloalkanes’. For the very reason that makes it possible for thousands of people to be employed in the car industry, including in technical jobs, without knowing what 2,2,4-Trimethylpentane is (an organic compound that makes it less likely that your vehicle will go up in flames when you turn on the engine).

Engineering is not science.

While engineers busy themselves with building new technologies out of the resources found in the natural world, scientists attempt to elucidate the structure of nature itself. Engineering tends to be more attractive than science: a fast car elegantly following the curves of a road makes more of an impression than the sticky black stuff coming out of an oil rig, let alone its chemical formula. And still, without nature, there would be no human artefact.

This post is an invitation to look beyond the colourful Formula Ones of Artificial Intelligence and take a trip into their combustion engines, all the way down to the hydrocarbons that power their pistons. There, we will find the dry natural phenomenon without which no intelligence would emerge. It is called meaning and its formula has not yet been fully discovered. But we already know that extracting, generating, and transforming it comes with incredibly high stakes. 


## The sci-fi of meaning

Any scientific field has moonshot applications which have so far remained the preserve of science fiction. Tapping into meaning could take us far beyond the science fictions of other fields, and also reveal the path to making them a reality. Imagine that semantics has been ‘solved’, and imagine a machine – let’s call it Minerva – that is fed with exactly the right mixture of meaning representations. What could Minerva do? Like a novelist, Minerva would be able to invent entire new worlds, with their landscapes, social structures and histories, with the people, creatures and everyday items that populate them, but also with minute descriptions of their physics, biologies and chemistries. Like a scientist, it could logically argue about what is true and false in those worlds, about what follows from their apparent structure, about the latent phenomena that explain their behaviours. Like an inventor, it would suggest the ways that the real world is to be changed in order to ascend to one of those imagined universes. Minerva would be artist, geneticist, astrophysicist, social scientist, politician, engineer and much, much more, within the confines of its microchip and memory. All its intellectual and creative abilities would derive from a single set of principles. And it would apply those principles flawlessly, away from human error. It would be the pocket calculator of thought.

The power of Minerva derives from three core skills: a) the ability to generate an infinity of possible worlds; b) the ability to tell what is true or false in a certain possible world; and c) the ability to logically derive new facts from true premises. Visit any entry-level course on semantics, and you will learn that all three are aspects of meaning. Humans master them in theory, but often fail to deploy them in practice, partly due to evolutionary limitations. A machine endowed with them, however, would spark innovation at an unprecedented rate. To build it, we just need to find out how to convert data into the right form.

This is unfortunately rather tricky.

The recent public discourse on AI has popularised the idea that training larger neural networks on larger amounts of data, with increasingly powerful hardware, will eventually lead to the emergence of intelligence. This strategy may be fine for now, in a context where computational power is centralised and owned by a few large corporations which, like the old oil giants, provide universal access to the fuel of contemporary economy, in the form of basic applications. It may not be fine anymore if computation becomes decentralised. Above all, this strategy is problematic if we want to know what kind of intelligence will emerge given a particular computational architecture. 

Working in the shadow of AI, Computational Semantics has been squeezing data into meaning representations for over fifty years, looking for the specific properties that would indicate their suitability for reasoning, thinking and creating. It has ways to pack the world – everything from the fragility of glass objects to the emotion of falling in love – into neat matrices of real numbers. It knows how to test which configurations of numbers will best predict the smashing of a champagne flute or the likely development of a budding romance in the mind of the machine. It knows which configurations, by definition, prevent the emergence of core cognitive skills. One day, who knows, it may even find the magic configuration which expresses everything humans can ever perceive, think or feel. There will be serious ethical issues to be solved at this point, so perhaps we should hope that it never happens. [...]
